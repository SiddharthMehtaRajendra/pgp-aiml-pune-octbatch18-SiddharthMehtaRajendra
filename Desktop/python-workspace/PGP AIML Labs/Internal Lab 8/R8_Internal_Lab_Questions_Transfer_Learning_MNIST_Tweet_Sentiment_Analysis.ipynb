{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"R8_Internal_Lab_Questions.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"text","id":"NFfDTfhlaEI_"},"cell_type":"markdown","source":["# Transfer Learning MNIST"]},{"metadata":{"colab_type":"text","id":"rNwbqCFRaEJC"},"cell_type":"markdown","source":["* Train a simple convnet on the MNIST dataset the first 5 digits [0..4].\n","* Freeze convolutional layers and fine-tune dense layers for the classification of digits [5..9]."]},{"metadata":{"colab_type":"text","id":"YUB1uDW_8XIy"},"cell_type":"markdown","source":["## 1. Import necessary libraries for the model"]},{"metadata":{"colab_type":"code","id":"Rsj4t5HTaEJE","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"IXrn3heBaEJa"},"cell_type":"markdown","source":["## 2. Import MNIST data and create 2 datasets with one dataset having digits from 0 to 4 and other from 5 to 9 "]},{"metadata":{"colab_type":"code","id":"pjDuiK6ztgOK","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"9qU14lYL9A5g"},"cell_type":"markdown","source":["## 3. Print x_train, y_train, x_test and y_test for both the datasets"]},{"metadata":{"colab_type":"code","id":"Z9OrszhJ0SgJ","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"sJswV4xk9jQS","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"cB9BPFzr9oDF"},"cell_type":"markdown","source":["## ** 4. Let us take only the dataset (x_train, y_train, x_test, y_test) for Integers 0 to 4 in MNIST **\n","## Reshape x_train and x_test to a 4 Dimensional array (channel = 1) to pass it into a Conv2D layer"]},{"metadata":{"colab_type":"code","id":"FlQRPfFzaEJx","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"jLQr-b3F-hw8"},"cell_type":"markdown","source":["## 5. Normalize x_train and x_test by dividing it by 255"]},{"metadata":{"colab_type":"code","id":"PlEZIAG5-g2I","colab":{}},"cell_type":"code","source":["\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"pytVBaw4-vMi"},"cell_type":"markdown","source":["## 6. Use One-hot encoding to divide y_train and y_test into required no of output classes"]},{"metadata":{"colab_type":"code","id":"V48xiua4-uUi","colab":{}},"cell_type":"code","source":["\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"elPkI44g_C2b"},"cell_type":"markdown","source":["## 7. Build a sequential model with 2 Convolutional layers with 32 kernels of size (3,3) followed by a Max pooling layer of size (2,2) followed by a drop out layer to be trained for classification of digits 0-4  "]},{"metadata":{"colab_type":"code","id":"MU09mm9F89gO","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"sJQaycRO_3Au"},"cell_type":"markdown","source":["## 8. Post that flatten the data and add 2 Dense layers with 128 neurons and neurons = output classes with activation = 'relu' and 'softmax' respectively. Add dropout layer inbetween if necessary  "]},{"metadata":{"colab_type":"code","id":"vOZeRbK7t9AT","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"my1P09bxAv8H"},"cell_type":"markdown","source":["## 9. Print the training and test accuracy"]},{"metadata":{"colab_type":"code","id":"yf7F8Gdutbf0","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"z78o3WIjaEJ3"},"cell_type":"markdown","source":["## 10. Make only the dense layers to be trainable and convolutional layers to be non-trainable"]},{"metadata":{"colab_type":"code","id":"brN7VZHFaEJ4","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"4opnW7o0BJ8P"},"cell_type":"markdown","source":["## 11. Use the model trained on 0 to 4 digit classification and train it on the dataset which has digits 5 to 9  (Using Transfer learning keeping only the dense layers to be trainable)"]},{"metadata":{"colab_type":"code","id":"lCFcYHTm6-cE","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"DITyAt3t7Tto","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"SoDozqghCJZ4"},"cell_type":"markdown","source":["## 12. Print the accuracy for classification of digits 5 to 9"]},{"metadata":{"colab_type":"code","id":"9fCxgb5s49Cj","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"LRWizZIpCUKg","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"FU-HwvIdH0M-","colab_type":"text"},"cell_type":"markdown","source":["## Sentiment analysis <br> \n","\n","The objective of the second problem is to perform Sentiment analysis from the tweets data collected from the users targeted at various mobile devices.\n","Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."]},{"metadata":{"id":"nAQDiZHRH0M_","colab_type":"text"},"cell_type":"markdown","source":["### 13. Read the dataset (tweets.csv) and drop the NA's while reading the dataset"]},{"metadata":{"id":"3eXGIe-SH0NA","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"CWeWe1eJH0NF","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"jPJvTjefH0NI","colab_type":"text"},"cell_type":"markdown","source":["### 14. Preprocess the text and add the preprocessed text in a column with name `text` in the dataframe."]},{"metadata":{"id":"5iec5s9gH0NI","colab_type":"code","colab":{}},"cell_type":"code","source":["def preprocess(text):\n","    try:\n","        return text.decode('ascii')\n","    except Exception as e:\n","        return \"\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"EQSmqA-vH0NT","colab_type":"code","colab":{}},"cell_type":"code","source":["data['text'] = [preprocess(text) for text in data.tweet_text]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7kX-WoJDH0NV","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"OGWB3P2WH0NY","colab_type":"text"},"cell_type":"markdown","source":["### 15. Consider only rows having Positive emotion and Negative emotion and remove other rows from the dataframe."]},{"metadata":{"id":"bdgA_8N2H0NY","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"_Jlu-reIH0Na","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"SotCRvkDH0Nf","colab_type":"text"},"cell_type":"markdown","source":["### 16. Represent text as numerical data using `CountVectorizer` and get the document term frequency matrix\n","\n","#### Use `vect` as the variable name for initialising CountVectorizer."]},{"metadata":{"id":"YcbkY4sgH0Ng","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"KyXtZGr-H0Nl","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z4LUM-XPH0Nn","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"aIdZYxJtH0Nq","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"5pxd5fSHH0Nt","colab_type":"text"},"cell_type":"markdown","source":["### 17. Find number of different words in vocabulary"]},{"metadata":{"id":"p1DQ2LdNH0Nu","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"dwtgjTBeH0Ny","colab_type":"text"},"cell_type":"markdown","source":["#### Tip: To see all available functions for an Object use dir"]},{"metadata":{"id":"2n_iCcTNH0N0","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ShA6D8jKH0N5","colab_type":"text"},"cell_type":"markdown","source":["### 18. Find out how many Positive and Negative emotions are there.\n","\n","Hint: Use value_counts on that column"]},{"metadata":{"id":"q7LAl5pzH0N6","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"IUvgj0FoH0N9","colab_type":"text"},"cell_type":"markdown","source":["### 19. Change the labels for Positive and Negative emotions as 1 and 0 respectively and store in a different column in the same dataframe named 'Label'\n","\n","Hint: use map on that column and give labels"]},{"metadata":{"id":"YftKwFv7H0N9","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"3YErwYLCH0N_","colab_type":"text"},"cell_type":"markdown","source":["### 20. Define the feature set (independent variable or X) to be `text` column and `labels` as target (or dependent variable)  and divide into train and test datasets"]},{"metadata":{"id":"lNkwrGgEH0OA","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q5nlCuaaH0OD","colab_type":"text"},"cell_type":"markdown","source":["## 21. **Predicting the sentiment:**\n","\n","\n","### Use Naive Bayes and Logistic Regression and their accuracy scores for predicting the sentiment of the given text"]},{"metadata":{"id":"2AbVYssaH0OE","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ktXrLhmOH0Of","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"clv2X0kKH0Ok","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"K86LRMfdH0Ou","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"sw-0B33tH0Ox","colab_type":"text"},"cell_type":"markdown","source":["## 22. Create a function called `tokenize_predict` which can take count vectorizer object as input and prints the accuracy for x (text) and y (labels)"]},{"metadata":{"id":"okCTOs1TH0Oy","colab_type":"code","colab":{}},"cell_type":"code","source":["def tokenize_test(vect):\n","    x_train_dtm = vect.fit_transform(x_train)\n","    print('Features: ', x_train_dtm.shape[1])\n","    x_test_dtm = vect.transform(x_test)\n","    nb = MultinomialNB()\n","    nb.fit(x_train_dtm, y_train)\n","    y_pred_class = nb.predict(x_test_dtm)\n","    print('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JxZ8jfPEH0O0","colab_type":"text"},"cell_type":"markdown","source":["### Create a count vectorizer function which includes n_grams = 1,2  and pass it to tokenize_predict function to print the accuracy score"]},{"metadata":{"id":"kdCyAN_IH0O0","colab_type":"code","colab":{}},"cell_type":"code","source":["\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"axepytmgH0O4","colab_type":"text"},"cell_type":"markdown","source":["### Create a count vectorizer function with stopwords = 'english'  and pass it to tokenize_predict function to print the accuracy score"]},{"metadata":{"id":"HToGkq7vH0O4","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"iOIlJRxoH0O7","colab_type":"text"},"cell_type":"markdown","source":["### Create a count vectorizer function with stopwords = 'english' and max_features =300  and pass it to tokenize_predict function to print the accuracy score"]},{"metadata":{"id":"6fUhff-oH0O8","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"S2KZNWVkH0PA","colab_type":"text"},"cell_type":"markdown","source":["### Create a count vectorizer function with n_grams = 1,2  and max_features = 15000  and pass it to tokenize_predict function to print the accuracy score"]},{"metadata":{"id":"3v9XD082H0PB","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"We3JK_SRH0PO","colab_type":"text"},"cell_type":"markdown","source":["### Create a count vectorizer function with n_grams = 1,2  and include terms that appear at least 2 times (min_df = 2)  and pass it to tokenize_predict function to print the accuracy score"]},{"metadata":{"id":"fUHrfDCyH0PP","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"3H4k_lVZH0PS","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}