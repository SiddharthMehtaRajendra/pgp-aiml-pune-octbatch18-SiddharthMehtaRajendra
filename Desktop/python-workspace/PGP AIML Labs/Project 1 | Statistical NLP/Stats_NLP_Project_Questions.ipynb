{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Rc_ahEnTF9m"
   },
   "source": [
    "# Predict tags on StackOverflow with linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5hmogPBTF9p"
   },
   "source": [
    "In this assignment you will learn how to predict tags for posts from [StackOverflow](https://stackoverflow.com). To solve this task you will use multilabel classification approach.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "In this task you will need the following libraries:\n",
    "- [Numpy](http://www.numpy.org) — a package for scientific computing.\n",
    "- [Pandas](https://pandas.pydata.org) — a library providing high-performance, easy-to-use data structures and data analysis tools for the Python\n",
    "- [scikit-learn](http://scikit-learn.org/stable/index.html) — a tool for data mining and data analysis.\n",
    "- [NLTK](http://www.nltk.org) — a platform to work with natural language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zSq4Uzh6TF9q"
   },
   "source": [
    "### Data\n",
    "\n",
    "You can find all data required for this assignment into the folder `/data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2V1gba1KTF9r"
   },
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WnvsWcP9TF9t"
   },
   "source": [
    "For this assignment you will need to use a list of stop words. It can be downloaded from *nltk*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "R-RxVRvsTF9u",
    "outputId": "bb9bb432-14c0-4fb5-878c-e02bd816423e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/siddharthmehta/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ErHWjimITF91"
   },
   "source": [
    "In this task you will deal with a dataset of post titles from StackOverflow. You are provided a split to 3 sets: *train*, *validation* and *test*. All corpora (except for *test*) contain titles of the posts and corresponding tags (100 tags are available). The *test* set doesn't contain answers. Upload the corpora using *pandas* and look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ufeO-nfVGha"
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDahiblaU-e7"
   },
   "source": [
    "Literal_eval package takes care of the preprocessing for the string so that it can be used in python. To know more on literal_eval please see the below documentation <br>\n",
    "https://kite.com/python/docs/ast.literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bubX7TSLVLXR"
   },
   "source": [
    "## Task 1: Create training, testing and validation data from the files given. Use title to be the independent variable and tags to be the dependent variable ( 5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KBFMf3bhVPb_"
   },
   "source": [
    "Note: Ensure you apply literal_eval function on the tags column to ensure all the tags are readable in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x8iH7o77TF96"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.tsv\", header=0,delimiter=\"\\t\", quoting=3)\n",
    "test_data = pd.read_csv(\"test.tsv\", header=0,delimiter=\"\\t\", quoting=3)\n",
    "validation_data = pd.read_csv(\"validation.tsv\", header=0,delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPaUfSVvTF99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 2)\n",
      "(20000, 1)\n",
      "(30000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(validation_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to draw a stacked dotplot in R?</td>\n",
       "      <td>['r']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mysql select all records where a datetime fiel...</td>\n",
       "      <td>['php', 'mysql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to terminate windows phone 8.1 app</td>\n",
       "      <td>['c#']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get current time in a specific country via jquery</td>\n",
       "      <td>['javascript', 'jquery']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Configuring Tomcat to Use SSL</td>\n",
       "      <td>['java']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                      tags\n",
       "0                How to draw a stacked dotplot in R?                     ['r']\n",
       "1  mysql select all records where a datetime fiel...          ['php', 'mysql']\n",
       "2             How to terminate windows phone 8.1 app                    ['c#']\n",
       "3  get current time in a specific country via jquery  ['javascript', 'jquery']\n",
       "4                      Configuring Tomcat to Use SSL                  ['java']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warning: mysql_query() expects parameter 2 to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>get click coordinates from &lt;input type='image'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to implement cloud storage for media asset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is catcomplete in jQuery's autocomplete p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Error building Android app with Cordova 3.1 CLI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0  Warning: mysql_query() expects parameter 2 to ...\n",
       "1  get click coordinates from <input type='image'...\n",
       "2  How to implement cloud storage for media asset...\n",
       "3  What is catcomplete in jQuery's autocomplete p...\n",
       "4    Error building Android app with Cordova 3.1 CLI"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why odbc_exec always fail?</td>\n",
       "      <td>['php', 'sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Access a base classes variable from within a c...</td>\n",
       "      <td>['javascript']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Content-Type \"\"application/json\"\" not require...</td>\n",
       "      <td>['ruby-on-rails', 'ruby']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sessions in Sinatra: Used to Pass Variable</td>\n",
       "      <td>['ruby', 'session']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Getting error - type \"\"json\"\" does not exist ...</td>\n",
       "      <td>['ruby-on-rails', 'ruby', 'json']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                         Why odbc_exec always fail?   \n",
       "1  Access a base classes variable from within a c...   \n",
       "2  \"Content-Type \"\"application/json\"\" not require...   \n",
       "3         Sessions in Sinatra: Used to Pass Variable   \n",
       "4  \"Getting error - type \"\"json\"\" does not exist ...   \n",
       "\n",
       "                                tags  \n",
       "0                     ['php', 'sql']  \n",
       "1                     ['javascript']  \n",
       "2          ['ruby-on-rails', 'ruby']  \n",
       "3                ['ruby', 'session']  \n",
       "4  ['ruby-on-rails', 'ruby', 'json']  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title' 'tags']\n",
      "['title']\n",
      "['title' 'tags']\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns.values)\n",
    "print(test_data.columns.values)\n",
    "print(validation_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USlubitlTF-G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to draw a stacked dotplot in R?\n",
      "['r']\n"
     ]
    }
   ],
   "source": [
    "print(train_data.title[0])\n",
    "print(train_data.tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"tags\"] = train_data[\"tags\"].apply(literal_eval)\n",
    "validation_data[\"tags\"] = validation_data[\"tags\"].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.loc[:, train_data.columns == 'title']\n",
    "X_val = validation_data.loc[:, validation_data.columns == 'title']\n",
    "X_test = test_data.loc[:, test_data.columns == 'title']\n",
    "Y_train = train_data.loc[:, train_data.columns == 'tags']\n",
    "Y_val = validation_data.loc[:, validation_data.columns == 'tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 1 columns):\n",
      "title    100000 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 781.3+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[r]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[php, mysql]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[c#]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[javascript, jquery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[java]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tags\n",
       "0                   [r]\n",
       "1          [php, mysql]\n",
       "2                  [c#]\n",
       "3  [javascript, jquery]\n",
       "4                [java]"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bcb3kXUSTF-M"
   },
   "source": [
    "## Task 2 (Pre-processing). Implement the function *text_prepare* following the instructions. After that, run the function *test_test_prepare* to test it on tiny cases. (10 points)\n",
    "\n",
    "One of the most known difficulties when working with natural data is that it's unstructured. For example, if you use it \"as is\" and extract tokens just by splitting the titles by whitespaces, you will see that there are many \"weird\" tokens like *3.5*, *?*,  *{}*, etc. To prevent the problems, it's usually useful to prepare the data in a custom way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PBSchmxtTF-N"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iI1plv6WTF-R"
   },
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def text_prepare(text): ### The function will take in text and lower case it remove the stopwords, symbols and return it.\n",
    "    text = text.lower()            ### Write a code which can change the input text to lowercase.\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, \" \", text)             ### Write a code which replaces REPLACE_BY_SPACE_RE (above mentioned) symbols by space in text\n",
    "    text = re.sub(BAD_SYMBOLS_RE, \"\", text)             ### Write a code which deletes symbols which are in BAD_SYMBOLS_RE (above mentioned) from text\n",
    "    text = [w for w in text.split(\" \") if not w in STOPWORDS]  \n",
    "    ### Write a code which deletes stopwords from text\n",
    "    return \" \".join(text)\n",
    "\n",
    "def label_prepare(label):\n",
    "    return \" \".join(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5LQEgMATF-Y"
   },
   "outputs": [],
   "source": [
    "def test_text_prepare():\n",
    "    examples = [\"SQL Server- any equivalent of Excel's CHOOSE function?\",\n",
    "                \"How to free c++ memory vector<int>* arr?\"]\n",
    "    answers = [\"sql server equivalent excels choose function\", \n",
    "               \"free c++ memory vectorint arr\"]\n",
    "    for ex, ans in zip(examples, answers):\n",
    "        if text_prepare(ex) != ans:\n",
    "            print(text_prepare(ex))\n",
    "            return \"Wrong answer for the case: '%s'\" % ex\n",
    "    return 'Basic tests are passed.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6t2DpralVokG"
   },
   "source": [
    "Execute the test_text_prepare function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihi8I2yQTF-b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Basic tests are passed.'"
      ]
     },
     "execution_count": 921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ettHAZ8eVt1R"
   },
   "source": [
    "*Note: You should pass the above test to ensure the text preprocessing is done before our analysis*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QV5JC6HXTF-k"
   },
   "source": [
    "Now we can preprocess the titles using function *text_prepare* and  making sure that the headers don't have bad symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gOZKuHnGTF-k"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddharthmehta/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/siddharthmehta/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/siddharthmehta/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Users/siddharthmehta/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train[\"title\"] = X_train[\"title\"].apply(text_prepare)\n",
    "X_val[\"title\"] = X_val[\"title\"].apply(text_prepare)\n",
    "X_test[\"title\"] = X_test[\"title\"].apply(text_prepare)\n",
    "\n",
    "Y_train[\"tags\"] = Y_train[\"tags\"].apply(label_prepare)\n",
    "Y_val[\"tags\"] = Y_val[\"tags\"].apply(label_prepare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfWls32MV5Uu"
   },
   "source": [
    "Print the top 5 elements in x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3BP3LiGsTF-o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = X[\"title\"].size\n",
    "num_tags = Y[\"tags\"].size\n",
    "\n",
    "def convertWordsToList(feature_data):\n",
    "    clean_train_words = []\n",
    "    num_words = feature_data[\"title\"].size\n",
    "    for i in range( 0, num_words):\n",
    "        list_words = feature_data[\"title\"][i].split(\" \")\n",
    "        for word in list_words:\n",
    "            if(word == ''):\n",
    "                continue\n",
    "            clean_train_words.append(word)\n",
    "    return clean_train_words\n",
    "\n",
    "def convertTagsToList(label_data):  \n",
    "    clean_train_tags = []\n",
    "    num_tags = label_data[\"tags\"].size\n",
    "    for i in range( 0, num_tags):\n",
    "        list_tags = label_data[\"tags\"][i].split(\" \")\n",
    "        for tag in list_tags:\n",
    "            clean_train_tags.append(tag)\n",
    "    return clean_train_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = convertWordsToList(X_train)\n",
    "X_val_clean = convertWordsToList(X_val)\n",
    "X_test_clean = convertWordsToList(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_clean = convertTagsToList(Y_train)\n",
    "Y_val_clean = convertTagsToList(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "At_ZTeqTTF-t"
   },
   "source": [
    "## Task 2 (WordsTagsCount) - Find 3 most popular tags and 3 most popular words in the train data. - 5 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2mT1f7gWKSu"
   },
   "source": [
    "Note: The words which appear the most are considered as popular in this case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-eQoxipTF-v"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "counter_words = collections.Counter(X_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Words: \n",
      " [('using', 8278), ('php', 5614), ('java', 5501)]\n"
     ]
    }
   ],
   "source": [
    "words_counts = dict(counter_words.items())\n",
    "print(\"Most Common Words: \\n\", counter_words.most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_tags = collections.Counter(Y_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Tags: \n",
      " [('javascript', 19078), ('c#', 19077), ('java', 18661)]\n"
     ]
    }
   ],
   "source": [
    "tags_counts = dict(counter_tags.items())\n",
    "print(\"Most Common Tags: \\n\", counter_tags.most_common(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkwg8_WNTF-3"
   },
   "source": [
    "We are assuming that *tags_counts* and *words_counts* are dictionaries like `{'some_word_or_tag': frequency}`. After applying the sorting procedure, results will be look like this: `[('most_popular_word_or_tag', frequency), ('less_popular_word_or_tag', frequency), ...]`.\n",
    "\n",
    "eg: \n",
    "Tag 1 - 100 Tag 2 - 65 Tag 3 - 250 <br>\n",
    "after sorting looks like, <br>\n",
    "Tag 3 - 250 Tag 1 - 100 Tag 2 - 65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xk7M4uJ_TF-8"
   },
   "source": [
    "## Task - 3 Transforming text to a vector (10 points)\n",
    "\n",
    "Machine Learning algorithms work with numeric data and we cannot use the provided text data \"as is\". There are many ways to transform text data to numeric vectors. In this task you will try to use two of them.\n",
    "\n",
    "#### Bag of words\n",
    "\n",
    "One of the well-known approaches is a *bag-of-words* representation. To create this transformation, follow the steps:\n",
    "1. Find *N* most popular words in train corpus and numerate them. Now we have a dictionary of the most popular words.\n",
    "2. For each title in the corpora create a zero vector with the dimension equals to *N*.\n",
    "3. For each text in the corpora iterate over words which are in the dictionary and increase by 1 the corresponding coordinate.\n",
    "\n",
    "Let's try to do it for a toy example. Imagine that we have *N* = 4 and the list of the most popular words is \n",
    "\n",
    "    ['hi', 'you', 'me', 'are']\n",
    "\n",
    "Then we need to numerate them, for example, like this: \n",
    "\n",
    "    {'hi': 0, 'you': 1, 'me': 2, 'are': 3}\n",
    "\n",
    "And we have the text, which we want to transform to the vector:\n",
    "\n",
    "    'hi how are you'\n",
    "\n",
    "For this text we create a corresponding zero vector \n",
    "\n",
    "    [0, 0, 0, 0]\n",
    "    \n",
    "And iterate over all words, and if the word is in the dictionary, we increase the value of the corresponding position in the vector:\n",
    "\n",
    "    'hi':  [1, 0, 0, 0]\n",
    "    'how': [1, 0, 0, 0] # word 'how' is not in our dictionary\n",
    "    'are': [1, 0, 0, 1]\n",
    "    'you': [1, 1, 0, 1]\n",
    "\n",
    "The resulting vector will be \n",
    "\n",
    "    [1, 1, 0, 1]\n",
    "   \n",
    "Implement the described encoding in the function *my_bag_of_words* with the size of the dictionary equals to 5000. To find the most common words use train data. You can test your code using the function *test_my_bag_of_words*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ER1oq48TF-9"
   },
   "outputs": [],
   "source": [
    "DICT_SIZE = 5000\n",
    "words_counts = dict(counter_words.most_common(DICT_SIZE))\n",
    "INDEX_TO_WORDS = sorted(words_counts.keys(), key = lambda x:words_counts[x], reverse = True)\n",
    "WORDS_TO_INDEX = {word:i for i,word in enumerate(INDEX_TO_WORDS)}\n",
    "\n",
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    result_vector = np.zeros(dict_size)\n",
    "    for ex in zip(text):\n",
    "        for word in ex:\n",
    "            if word in words_to_index:\n",
    "                result_vector[words_to_index[word]] += 1\n",
    "        return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('draw stacked dotplot r',)\n"
     ]
    }
   ],
   "source": [
    "for ex in zip(X_train[\"title\"]):\n",
    "    print(ex)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnLYWnsaTF_A"
   },
   "outputs": [],
   "source": [
    "def test_my_bag_of_words():\n",
    "    words_to_index = {'hi': 0, 'you': 1, 'me': 2, 'are': 3}\n",
    "    examples = ['hi how are you']\n",
    "    answers = [[1, 1, 0, 1]]\n",
    "    for ex, ans in zip(examples, answers):\n",
    "        if (my_bag_of_words(ex, words_to_index, 4) != ans).any():\n",
    "            return \"Wrong answer for the case: '%s'\" % ex\n",
    "    return 'Basic tests are passed.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOlSiUqEW3jD"
   },
   "source": [
    "Execute the test_text_prepare function <br>\n",
    "*<u>Note:</u> You should pass the above test to ensure BOW is working correctly!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqWhoF24TF_D"
   },
   "outputs": [],
   "source": [
    "#Kindly Ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BXW3ALCITF_H"
   },
   "source": [
    "Now apply the implemented function to all samples (this might take up to a minute):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m39xHB2yTF_H"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import sparse as sp_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DZwPWB1TF_K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (1, 5000)\n",
      "X_val shape  (1, 5000)\n",
      "X_test shape  (1, 5000)\n"
     ]
    }
   ],
   "source": [
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(X_train[\"title\"], WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(X_val[\"title\"], WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(X_test[\"title\"], WORDS_TO_INDEX, DICT_SIZE)) for text in X_test])\n",
    "print('X_train shape ', X_train_mybag.shape)\n",
    "print('X_val shape ', X_val_mybag.shape)\n",
    "print('X_test shape ', X_test_mybag.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WPXTUeNSTF_N"
   },
   "source": [
    "As you might notice, we transform the data to sparse representation, to store the useful information efficiently. There are many types: of such representations, however sklearn algorithms can work only with  csr matrix, so we will use this one.<br>\n",
    "<u>Documentations on sparse matrix:</u> <br>\n",
    "(https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) \n",
    "(https://docs.scipy.org/doc/scipy/reference/sparse.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bOetzSLzTF_S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "sparse = X_train_mybag.transpose()\n",
    "non_zero_elements_count = sparse[11].count_nonzero()\n",
    "print(non_zero_elements_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYAFKGfKTF_V"
   },
   "source": [
    "## Task 4 - TF-IDF (5 points)\n",
    "\n",
    "The second approach extends the bag-of-words framework by taking into account total frequencies of words in the corpora. It helps to penalize too frequent words and provide better features space. \n",
    "\n",
    "Implement function *tfidf_features* using class  from *scikit-learn*. Use *train* corpus to train a vectorizer. Don't forget to take a look into the arguments that you can pass to it. We suggest that you filter out too rare words (occur less than in 5 titles) and too frequent words (occur more than in 90% of the titles). Also, use bigrams along with unigrams in your vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1s3uEKmjYpuh"
   },
   "source": [
    "## Write a function which takes x_train, x_val and x_test as input and return the tf-idf features of the same and the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o6V7FPirTF_i"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def tfidf_features(X_train, X_val, X_test):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df = 0.90, min_df = 5, ngram_range = (1,2))\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.fit_transform(X_test)\n",
    "    X_val_tfidf = tfidf_vectorizer.fit_transform(X_val)\n",
    "    return X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ySnV2zCBTF_p"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train[\"title\"].tolist(), X_val[\"title\"].tolist(), X_test[\"title\"].tolist())\n",
    "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_aopTTNL5G1"
   },
   "source": [
    "Print the index of string \"C#\" in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZ-3wqTTMCRi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given Key not Present\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for key in tfidf_vocab.keys():\n",
    "    if (tfidf_vocab.get(key) == \"C#\"):\n",
    "        print(key)\n",
    "        count = count + 1\n",
    "if(count == 0):\n",
    "    print(\"Given Key not Present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYYO2kdiTF_6"
   },
   "source": [
    "## Task 5: Classification (15 points)\n",
    "MultiLabel classifier\n",
    "\n",
    "As we have noticed before, in this task each example can have multiple tags. To deal with such kind of prediction, we need to transform labels in a binary form and the prediction will be a mask of 0s and 1s. For this purpose it is convenient to use MultiLabelBinarizer from sklearn. <br>\n",
    "<u>Documentation:</u> <br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojeCe_e_TF_7"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8JYQr8YTF_-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddharthmehta/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:935: UserWarning: unknown class(es) ['a', 'g', 's', 't'] will be ignored\n",
      "  .format(sorted(unknown, key=str)))\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer(classes=sorted(counter_tags.keys()))\n",
    "y_train = mlb.fit_transform(Y_train)\n",
    "y_val = mlb.fit_transform(Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qN1NUA3DTGAB"
   },
   "source": [
    "In this task we suggest to use One-vs-Rest approach, which is implemented in [OneVsRestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html) class. In this approach *k* classifiers (= number of tags) are trained. As a basic classifier, use [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). It is one of the simplest methods, but often it performs good enough in text classification tasks. It might take some time, because a number of classifiers to train is large.\n",
    "\n",
    "**OneVsRest multi-label strategy**\n",
    "\n",
    "The Multi-label algorithm accepts a binary mask over multiple labels. The result for each prediction will be an array of 0s and 1s marking which class labels apply to each row input sample.\n",
    "\n",
    "**Logistic Regression & SVM**\n",
    "\n",
    "OneVsRest strategy can be used for multi-label learning, where a classifier is used to predict multiple labels for instance. LR & SVM supports multi-class, but we are in a multi-label scenario, therefore, we wrap classifiers in the OneVsRestClassifier.\n",
    "\n",
    "*If you want to learn more about OneVsRest, check out these links:*\n",
    "- *https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5*\n",
    "- *https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff*\n",
    "- *https://medium.com/coinmonks/multi-label-classification-blog-tags-prediction-using-nlp-b0b5ee6686fc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Pj6MDkbTGAC"
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUHZR2TWTGAF"
   },
   "outputs": [],
   "source": [
    "def train_classifier(x_tr, y_tr):\n",
    "    # Create and fit LogisticRegression and LinearSVC wraped into OneVsRestClassifier.\n",
    "    clf = OneVsRestClassifier(LogisticRegression(solver = 'sag'))\n",
    "    clf.fit(x_tr, y_tr)\n",
    "    return clf  ### clf is the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k660NfRFTGAL"
   },
   "source": [
    "Train the classifiers for different data transformations: *bag-of-words* and *tf-idf*.\n",
    "classifier_mybag = model for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jXyhN-yDTGAP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.net',\n",
       " 'ajax',\n",
       " 'algorithm',\n",
       " 'android',\n",
       " 'angularjs',\n",
       " 'apache',\n",
       " 'arrays',\n",
       " 'asp.net',\n",
       " 'asp.net-mvc',\n",
       " 'c',\n",
       " 'c#',\n",
       " 'c++',\n",
       " 'class',\n",
       " 'cocoa-touch',\n",
       " 'codeigniter',\n",
       " 'css',\n",
       " 'csv',\n",
       " 'database',\n",
       " 'date',\n",
       " 'datetime',\n",
       " 'django',\n",
       " 'dom',\n",
       " 'eclipse',\n",
       " 'entity-framework',\n",
       " 'excel',\n",
       " 'facebook',\n",
       " 'file',\n",
       " 'forms',\n",
       " 'function',\n",
       " 'generics',\n",
       " 'google-maps',\n",
       " 'hibernate',\n",
       " 'html',\n",
       " 'html5',\n",
       " 'image',\n",
       " 'ios',\n",
       " 'iphone',\n",
       " 'java',\n",
       " 'javascript',\n",
       " 'jquery',\n",
       " 'json',\n",
       " 'jsp',\n",
       " 'laravel',\n",
       " 'linq',\n",
       " 'linux',\n",
       " 'list',\n",
       " 'loops',\n",
       " 'maven',\n",
       " 'mongodb',\n",
       " 'multithreading',\n",
       " 'mysql',\n",
       " 'node.js',\n",
       " 'numpy',\n",
       " 'objective-c',\n",
       " 'oop',\n",
       " 'opencv',\n",
       " 'osx',\n",
       " 'pandas',\n",
       " 'parsing',\n",
       " 'performance',\n",
       " 'php',\n",
       " 'pointers',\n",
       " 'python',\n",
       " 'python-2.7',\n",
       " 'python-3.x',\n",
       " 'qt',\n",
       " 'r',\n",
       " 'regex',\n",
       " 'rest',\n",
       " 'ruby',\n",
       " 'ruby-on-rails',\n",
       " 'ruby-on-rails-3',\n",
       " 'selenium',\n",
       " 'servlets',\n",
       " 'session',\n",
       " 'sockets',\n",
       " 'sorting',\n",
       " 'spring',\n",
       " 'spring-mvc',\n",
       " 'sql',\n",
       " 'sql-server',\n",
       " 'string',\n",
       " 'swift',\n",
       " 'swing',\n",
       " 'twitter-bootstrap',\n",
       " 'uitableview',\n",
       " 'unit-testing',\n",
       " 'validation',\n",
       " 'vb.net',\n",
       " 'visual-studio',\n",
       " 'visual-studio-2010',\n",
       " 'wcf',\n",
       " 'web-services',\n",
       " 'windows',\n",
       " 'winforms',\n",
       " 'wordpress',\n",
       " 'wpf',\n",
       " 'xaml',\n",
       " 'xcode',\n",
       " 'xml']"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(counter_tags.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ijQZCd9cTGAU"
   },
   "source": [
    "Now you can create predictions for the data. You will need two types of predictions: labels and scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0QT7uWddTGAV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predicted_labels_mybag = classifier_mybag.predict(X_val_mybag)\n",
    "y_val_predicted_scores_mybag = classifier_mybag.decision_function(X_val_mybag)\n",
    "\n",
    "y_val_predicted_labels_tfidf = classifier_tfidf.predict(X_val_tfidf)\n",
    "y_val_predicted_scores_tfidf = classifier_tfidf.decision_function(X_val_tfidf)\n",
    "\n",
    "y_val_predicted_labels_mybag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p9n0TEtHTGAj"
   },
   "source": [
    "Now, we would need to compare the results of different predictions, e.g. to see whether TF-IDF transformation helps or to try different regularization techniques in logistic regression. For all these experiments, we need to setup evaluation procedure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RVqAxDxqTGAk"
   },
   "source": [
    "## Evaluation (10 points)\n",
    "\n",
    "To evaluate the results we will use several classification metrics:\n",
    " - [Accuracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    " - [F1-score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n",
    " - [Area under ROC-curve](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
    " - [Area under precision-recall curve](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score) \n",
    " \n",
    "Make sure you are familiar with all of them. If you want a refresher, you can click the link to their documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_YmNhVsU9K9-"
   },
   "source": [
    "## Import the necessary libraries for the above metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBvrkOUYTGAl"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNkYBl_wTGAp"
   },
   "source": [
    "Define the function *print_evaluation_scores* which takes y_val and predicted as input calculates and prints the following output:\n",
    " - *accuracy*\n",
    " - *F1-score - Average = 'weighted'* \n",
    " - *Precision - Average = 'macro'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4nevWnhTGAq"
   },
   "outputs": [],
   "source": [
    "def print_evaluation_scores(y_val, predicted):\n",
    "    print(accuracy_score(y_val, predicted))\n",
    "    print(f1_score(y_val, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G92GIO4dTGAt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words\n",
      "Tfidf\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 30000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-961-f24f47e99ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#print_evaluation_scores(y_val, y_val_predicted_labels_mybag)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tfidf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint_evaluation_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_predicted_labels_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-956-0b328e756480>\u001b[0m in \u001b[0;36mprint_evaluation_scores\u001b[0;34m(y_val, predicted)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_evaluation_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 30000]"
     ]
    }
   ],
   "source": [
    "print('Bag-of-words')\n",
    "#print_evaluation_scores(y_val, y_val_predicted_labels_mybag)\n",
    "print('Tfidf')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kT7oso8ZTGAv"
   },
   "source": [
    "You might also want to plot some form of the [ROC curve](http://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc) for the case of multi-label classification. The input parameters for the roc curve are:\n",
    " - true labels\n",
    " - decision functions scores\n",
    " - number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4hbW3SeBVxz"
   },
   "source": [
    "Import the roc_auc function from the metrics.py file provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_9M0AI4TGAv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sZaymN4uTGA0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XwNpUEVLTGA2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9S3Ddz7LTGA3"
   },
   "source": [
    "## Task 4 (MultilabelClassification) - Optional \n",
    "** Once we have the evaluation set up, we suggest that you experiment a bit with training your classifiers. We will use *F1-score weighted* as an evaluation metric. Our recommendation:\n",
    "- compare the quality of the bag-of-words and TF-IDF approaches and chose one of them.\n",
    "- for the chosen one, try *L1* and *L2*-regularization techniques in Logistic Regression with different coefficients (e.g. C equal to 0.1, 1, 10, 100).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ers40KuOTGA4"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mdqTO269TGA8"
   },
   "source": [
    "When you are happy with the quality, create predictions for *test* set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M51F10f9TGBB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stats_NLP_Project_Questions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
